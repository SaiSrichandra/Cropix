{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting tensorflow to use GPU to train\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required components\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Layer, Flatten, Input, BatchNormalization, Activation, Dropout\n",
    "from keras_adabound import AdaBound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Image Data Generator to augment and feed images to the model\n",
    "datagen=ImageDataGenerator(rescale=1./255., validation_split=0.1, shear_range=0.1, zoom_range = 0.2, width_shift_range=10, height_shift_range=15, horizontal_flip = True, fill_mode = \"nearest\")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(directory = r\"D:/Crop Field Dataset/train\", subset = \"training\", batch_size = 32, seed = 42, shuffle = True, class_mode = \"categorical\", target_size=(227,227))\n",
    "\n",
    "valid_gen = datagen.flow_from_directory(directory = r\"D:/Crop Field Dataset/train\", subset = \"validation\", batch_size = 32, seed = 42, shuffle = True, class_mode = \"categorical\", target_size=(227,227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating number of steps in each epoch\n",
    "TRAIN_STEP = train_gen.n//train_gen.batch_size\n",
    "VALID_STEP = valid_gen.n//valid_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the neural network model\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,), kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "AlexNet.add(Dense(2048))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "AlexNet.add(Dense(1024))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(1000, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(9))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the layers in the model\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up required loss function and optimizers\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "Adam_opt = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "Adab=AdaBound(lr=1e-3, final_lr=0.01)\n",
    "loss_fun = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Callback to suspend training when required accuracy is reached\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.8040):\n",
    "            print(\"\\nReached 75.0% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training for 50 epochs with Adam Optimizer\n",
    "AlexNet.compile(optimizer = Adam_opt, loss = loss_fun, metrics = ['accuracy'])\n",
    "history = AlexNet.fit(train_gen, validation_data = valid_gen, epochs = 50, steps_per_epoch = TRAIN_STEP, validation_steps = VALID_STEP, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training for another 50 epochs with Adabound Optimizer\n",
    "AlexNet.compile(optimizer = Adab, loss = loss_fun, metrics = ['accuracy'])\n",
    "history2 = AlexNet.fit(train_gen, validation_data = valid_gen, epochs = 50, steps_per_epoch = TRAIN_STEP, validation_steps = VALID_STEP, callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "AlexNet.save(r\"D:/model_80.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the labels of classes\n",
    "label_map = (train_gen.class_indices)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting model to .tflite and quantizing it to use in mobile app\n",
    "new_model= tf.keras.models.load_model(filepath=r\"D:/model_80.h5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "with open(r\"D:/quantized_model.tflite\", \"wb\") as f:\n",
    "    f.write(quantized_and_pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "import cv2\n",
    "\n",
    "# read and resize the image\n",
    "img = cv2.imread(r\"D:\\Crop Field Dataset\\test\\corn\\test_img.jpg\")\n",
    "new_img = cv2.resize(img, (227, 227)).astype('float32')\n",
    "new_img = new_img/255.\n",
    "new_img = new_img.reshape(-1, 227, 227, 3)\n",
    "\n",
    "#Predict and show result\n",
    "arr = new_model.predict(new_img)\n",
    "print(np.argmax(arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_version",
   "language": "python",
   "name": "tgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
